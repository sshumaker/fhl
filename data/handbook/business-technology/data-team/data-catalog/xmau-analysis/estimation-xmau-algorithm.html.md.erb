---
layout: handbook-page-toc
title: "Self-Managed Metric Estimation Algorithm"
---

## On this page
{:.no_toc}

- TOC
{:toc}

---

## Introduction to Service Ping estimation

Self-Managed data arrives from [Service Ping](https://docs.gitlab.com/ee/development/service_ping/) 
which returns aggregated counts of user activity and other usage metrics for analysis. The 
Service Ping data we receive is incomplete as there are 3 types of installations that we need 
to estimate for:
1. Installations that opt out of sending us Service Ping
1. Installations that opt to send a subset of Service Ping metrics (i.e. operational metrics)
    * This applies to any metric where [`category = 'optional'`](https://metrics.gitlab.com/?q=optional)
1. Installations on older versions without the metric instrumented
    * Ex: If a metric is instrumented on 13.3, we need to estimate usage for installations 
    reporting on versions < 13.3

This leads to only a subset of the data being reported. Some data will be partial as we know 
there is an installation but we did not receive all the metrics we report on (whether due to 
version or metric opt-out). Some installations will never be seen and we cannot know how many of 
these exist as they opted-out of reporting Service Ping completely. The only moment we can 
identify these installations is when they create a subscription (not all installations make a 
subscription) and at this moment we can identify there is a self-managed installation even if 
it does not send ping. The subscription can choose whether it would like to report Service Ping 
or not.

To attempt to report the total MAU we then need to apply estimates on top of metrics and the 
aggregate to address the points above. 

The ultimate goal is to create estimation methodologies that meet the following criteria:

1. They are logically sound (i.e., we think they are reasonable for estimating usage) 
1. They produce reasonable results (ex: they do not produce extremely volatile metrics, which 
seem unlikely to reflect reality)
1. They are easy to explain and understand
1. They are auditable

If those criteria are not met, it is challenging to have trust in the integrity of the estimation 
and accept it as a viable solution for KPI reporting and analysis. The goal of this page is to 
enable greater understanding of why we generate estimations, who we generate them for, and what 
our current methodologies are. For the sake of transparency and to enable self-service exploration, 
the mechanisms and details of how and where we generate components of our methodologies are 
included throughout the page.

### Technical details

**What we know**

* The number of active subscriptions per month
* The number of active subscriptions that send GitLab service ping data each month
* The release version for each specific metric/counter and edition (CE vs EE) in Service Ping
  * Ex: we know that `redis_hll_counters.epics_usage.epics_usage_total_unique_counts_monthly` 
  was released in version 13.7 on CE and 13.8 on EE.

<details markdown=1>

<summary><b>Technical implementation details</b></summary>

* Identifying active subscriptions
  * Whether a subscription is "active" within a given month is determined by 1 of 2 things:
      1. The subscription's presence in [`fct_charge`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.fct_charge) 
  with a status of either  `Active` or `Cancelled`
      2. The subscription's presence in [`mart_ping_instance_metric_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.mart_ping_instance_metric_monthly) 
  (in other words, subscriptions that sent a ping), even if they were not found in [`fct_charge`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.fct_charge)
  * Details on active subscriptions at the subscription- and installation-level are surfaced in 
  [`rpt_ping_latest_subscriptions_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_latest_subscriptions_monthly)
* Counting active subscriptions that sent Service Ping
  * This is captured by a distinct count of subscriptions from [`mart_ping_instance_metric_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.mart_ping_instance_metric_monthly) 
* Determining when a metric was instrumented
  * This is determined by finding the MIN and MAX version where that metric exists on a given 
  edition within [`mart_ping_instance_metric_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.mart_ping_instance_metric_monthly)
  * This data is surfaced in [`rpt_ping_metric_first_last_versions`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_metric_first_last_versions)

</details>

**What we don't know**

* Number of active free installations
  * If a free installation does not send us Service Ping, we have no way of knowing it exists

Since we do not have visibility into the entire scope of the free Self-Managed universe, we need 
to rely on the behavior of paid installations to generate estimates.

## Current methodologies

Several different methodologies are available in the reporting models (ex: [`rpt_ping_metric_totals_w_estimates_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_metric_totals_w_estimates_monthly)). 
We use the field `estimation_grain` to differentiate the methodologies.

Right now, there are 2 components to each `estimation_grain`, a condition and a measure. 
The "condition" relates to the actual reporting from Service Ping, the "measure" is the value 
we will use to generate the estimate.

| Condition | Measure | `estimation_grain` |
| --- | --- | --- |
| On version with metric | Subscription count | `metric/version check - subscription based estimation`* |
| On version with metric | Seat count | `metric/version check - seat based estimation` |
| Reported metric | Subscription count | `reported metric - subscription based estimation` |
| Reported metric | Seat count | `reported metric - seat based estimation` |

_*This is the original methodology used in the legacy models._

### Assumptions

Given the knowns and unknowns, our current methodologies all make the following assumptions:

* Installations that do not report metrics behave the same as installations that send Service Ping
  * This means that we assume that free and paid installations act the same, that paid 
  installations that opt into sending Service Ping act the same as those who do not, etc
* Installations that do not report metrics adopt versions at the same rate as installations 
that send Service Ping
  * All editions and tiers are assumed to have the same version adoption rate
* Free installations opt into sending Service Ping at the same rate as paid installations

In the future, we hope to iterate on these methodologies in order to [address some of the issues 
with these assumptions](/handbook/business-technology/data-team/data-catalog/xmau-analysis/estimation-xmau-algorithm.html#areas-of-opportunity-for-iteration).

### Methodology conditions

We currently have 2 distinct conditions for our different methodologies:
1. Reporting on a version with the metric
1. Reporting the metric

#### On version with metric (metric/version check)

* `estimation_grain = 'metric/version check - subscription based estimation'`
  * First version of estimation used in legacy models
* `estimation_grain = 'metric/version check - seat based estimation'`

<br>

`Total xMAU (with estimate) = Recorded xMAU / % subscription count or seats on a version with the metric`

This condition leverages the ratio of subscriptions or seats (the measure) that _report on a version 
with the metric instrumented_. Since metrics are released on different GitLab versions across 
editions, this ratio is customized for each metric and edition. For metrics introduced on the 
same version, the ratio will be the same. (Ex: the ratio is the same for all metrics 
instrumented on EE version 13.3).

With this condition comes an additional assumption: all installations on a given 
version report all metrics. This does not take into account that some installations only send 
[`operational`](https://metrics.gitlab.com/?q=operational) metrics and opt out of sending 
[`optional`](https://metrics.gitlab.com/?q=optional) metrics. (Note: Not all xMAU metrics are 
considered to be operational).

<details markdown=1>

<summary><b>Technical implementation details</b></summary>

Whether a subscription meets this condition is determined in [`rpt_ping_subscriptions_on_versions_counts_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_subscriptions_on_versions_counts_monthly).

</details>

#### Reported metric

* `estimation_grain = 'reported metric - subscription based estimation'`
* `estimation_grain = 'reported metric - seat based estimation'`

<br>

`Total xMAU (with estimate) = Recorded xMAU / % subscription count or seats reporting metric`

This condition leverages the ratio of subscriptions or seats (the measure) that _report a 
metric_. Since not all installations report all metrics (see distinction above re: operational 
vs optional metrics), this ratio is customized for each metric.

This condition also adds an assumption: all metrics were instrumented on the same version of CE 
and EE. However, we know that metrics are instrumented on different versions. (Ex: `redis_hll_counters.epics_usage.epics_usage_total_unique_counts_monthly`
was released in version 13.7 on CE and 13.8 on EE)

<details markdown=1>

<summary><b>Technical implementation details</b></summary>

Whether a subscription meets this condition is determined in [`rpt_ping_subscriptions_reported_estimate_factors_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_subscriptions_reported_estimate_factors_monthly).

</details>

### Methodology measures

We currently have 2 distinct measures for our different methodologies:
1. Subscription count
1. Seat count

#### Subscription count

* `estimation_grain = 'metric/version check - subscription based estimation'`
  * First version of estimation used in legacy models
* `estimation_grain = 'reported metric - subscription based estimation'`

This measure leverages the actual count of active subscriptions that meet the given condition. 
This count is inclusive of both paid _and_ unpaid subscriptions (ex: OSS/EDU programs).

This measure carries another assumption: all installations have the same number of users. In 
other words, an installation with 5 seats is treated/weighted the same as one with 1000 seats.

<details markdown=1>

<summary><b>Technical implementation details</b></summary>

Subscription counts are determined by a subscription's presence in [`fct_charge`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.fct_charge) 
with a status of either `Active` or `Cancelled`, but we also include subscriptions appearing 
in [`mart_ping_instance_metric_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.mart_ping_instance_metric_monthly) 
(in other words, subscriptions that sent a ping) that were not found in [`fct_charge`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.fct_charge). 
This is surfaced in the model [`rpt_ping_latest_subscriptions_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_latest_subscriptions_monthly) 
with the field `latest_subsciption_id`. In the subsequent models like [`rpt_ping_subscriptions_reported_estimate_factors_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_subscriptions_reported_estimate_factors_monthly), 
a distinct count of `latest_subsciption_id` is used to determine the number of 
subscriptions meeting the condition and the number of potential subscriptions. When determining 
the ratio or percentage of subscriptions meeting the condition, we use the [`pct_w_counters` macro](https://gitlab-data.gitlab.io/analytics/#!/macro/macro.gitlab_snowflake.pct_w_counters), 
contains the following calculation: 

`DIV0({{ reporting_count }},({{ reporting_count }}+{{ no_reporting_count }}))`

This is synonymous with 

`count of subscriptions meeting condition / total subscription count`

The output of that macro is the % of subscriptions meeting the condition. We then apply that 
ratio to the recorded usage in the [`usage_estimation` macro](https://gitlab-data.gitlab.io/analytics/#!/macro/macro.gitlab_snowflake.usage_estimation) 
to generate the estimated usage. The macro applies the following calculation:

`{{ recorded_usage }} + DIV0(({{ recorded_usage }} * (1 - {{ percent_reporting }} )),{{ percent_reporting }} )`

This is synonymous with

`(recorded usage / % of subscriptions meeting condition) - recorded_usage`

The output of that macro is the estimated usage. The recorded, estimated, and total usage values 
are surfaced in [`rpt_ping_metric_totals_w_estimates_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_metric_totals_w_estimates_monthly), 
along with the raw inputs (count of total subscriptions, % of subscriptions meeting condition, etc).

</details>

#### Seat count

* `estimation_grain = 'metric/version check - seat based estimation'`
* `estimation_grain = 'reported metric - seat based estimation'`

This measure leverages the count of licensed seats associated with active subscriptions. 
This count is inclusive of seats associated with both paid _and_ unpaid subscriptions 
(ex: OSS/EDU programs).

This measure also brings the following assumption: license utilization is the same across all 
installations. In other words, we assume that the same share of seats is used, regardless of 
the installation's size.

<details markdown=1>

<summary><b>Technical implementation details</b></summary>

Seat counts are determined by `quantity` found within the [`fct_charge`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.fct_charge) 
model. This is surfaced as `total_licensed_users` in [`rpt_ping_subscriptions_reported_counts_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_subscriptions_reported_counts_monthly) 
and [`rpt_ping_subscriptions_on_versions_counts_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_subscriptions_on_versions_counts_monthly). 

When determining the ratio or percentage of seats meeting the condition, we use the [`pct_w_counters` macro](https://gitlab-data.gitlab.io/analytics/#!/macro/macro.gitlab_snowflake.pct_w_counters), 
contains the following calculation: 

`DIV0({{ reporting_count }},({{ reporting_count }}+{{ no_reporting_count }}))`

This is synonymous with 

`count of seats meeting condition / total seat count`

The output of that macro is the % of seats meeting the condition. We then apply that 
ratio to the recorded usage in the [`usage_estimation` macro](https://gitlab-data.gitlab.io/analytics/#!/macro/macro.gitlab_snowflake.usage_estimation) 
to generate the estimated usage. The macro applies the following calculation:

`{{ recorded_usage }} + DIV0(({{ recorded_usage }} * (1 - {{ percent_reporting }} )),{{ percent_reporting }} )`

This is synonymous with

`(recorded usage / % of seats meeting condition) - recorded_usage`

The output of that macro is the estimated usage. The recorded, estimated, and total usage values 
are surfaced in [`rpt_ping_metric_totals_w_estimates_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_metric_totals_w_estimates_monthly), 
along with the raw inputs (count of total seats, % of seats meeting condition, etc).

</details>

### Examples

In order to better understand how these methodologies translate into actual calculations, here 
are some examples covering each of the conditions and measures above. These examples use 
hypothetical data to facilitate the step-by-step calculations.

In both examples we are generating Total Create SMAU, including the 
estimate. The counter used as SMAU for the Create stage is `usage_activity_by_stage_monthly.create.action_monthly_active_users_project_repo`. 

#### On version with metric x Subscription count

To calculate the Estimated SMAU for `estimation_grain = 'metric/version check - subscription based estimation'`, 
we follow the following process for a given month:

1. Determine the number of active subscriptions during that month
    * **Active self-managed subscriptions: 5000**
    * This occurs in [`rpt_ping_subscriptions_reported_counts_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_subscriptions_reported_counts_monthly)
1. Determine when (on which version) the metric was first introduced
    * **`usage_activity_by_stage_monthly.create.action_monthly_active_users_project_repo` was 
  released on version 13.3 on both CE and EE**
    * This occurs in [`rpt_ping_metric_first_last_versions`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_metric_first_last_versions)
1. Calculate the % of subscriptions that sent us a service ping on a version with the metric 
instrumented (in this case, subscriptions on versions >= 13.3)
    * **% of subscriptions reporting on a version >= 13.3 = 3000/5000 = 60%**
    * This occurs in [`rpt_ping_subscriptions_on_versions_estimate_factors_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_subscriptions_on_versions_estimate_factors_monthly)
1. Calculate recorded SMAU split by delivery (Self-Managed vs SaaS)
    * **Recorded Self-Managed SMAU: 1M**
    * **SaaS SMAU: 800K**
    * This occurs in [`rpt_ping_metric_totals_w_estimates_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_metric_totals_w_estimates_monthly)
1. Calculate Total SMAU (with estimate)
    * **Total Self-Managed SMAU (with estimate) = Recorded SMAU / % of subscriptions on 13.3+ = 1M / 60% = 1.7M**
    * **Estimated uplift = (Recorded SMAU / % of subscriptions on 13.3+) - Recorded SMAU = 1.7M - 1M = 0.7M**
    * **Total SMAU (with estimate) = 1.0M (Recorded Self-Managed) + 0.7M (Estimated Self-Managed Uplift) + 800K (SaaS) = 2.5M**
    * This occurs in [`rpt_ping_metric_totals_w_estimates_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_metric_totals_w_estimates_monthly)

  <!--- Optional content that we could pull back into an example or elsewhere on the page in a future iteration
    * We can actually split the 5000 active subscriptions are split into 3 buckets:
      1. Subscriptions reporting on a version >= 13.3: 3000 subscriptions
      2. Subscriptions reporting on a version < 13.3: 700 subscriptions
      3. Subscriptions that did not send service ping: 1300 subscriptions
      * [This SiSense chart displays the split per month](https://app.periscopedata.com/app/gitlab/602123/Data-For-Product-Managers:-Supporting-Dashboard?widget=10065654&udv=953103)
  --->

#### Reported metric x Seat count

To calculate the Estimated SMAU for `estimation_grain = 'reported metric - seat based estimation'`, 
we follow the following process for a given month:

1. Determine the number of licensed seat tied to active subscriptions during that month
    * **Active self-managed seats: 1000000**
    * This occurs in [`rpt_ping_latest_subscriptions_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_latest_subscriptions_monthly) (subscription-level) and [`rpt_ping_subscriptions_reported_counts_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_subscriptions_reported_counts_monthly) (aggregated)
1. Calculate the % of seats that reported the metric
    * **% of seats reporting `usage_activity_by_stage_monthly.create.action_monthly_active_users_project_repo` = 530000/1000000 = 53%**
    * This occurs in [`rpt_ping_subscriptions_reported_estimate_factors_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_subscriptions_reported_estimate_factors_monthly)
1. Calculate recorded SMAU split by delivery (Self-Managed vs SaaS)
    * **Recorded Self-Managed SMAU: 1M**
    * **SaaS SMAU: 800K**
    * This occurs in [`rpt_ping_metric_totals_w_estimates_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_metric_totals_w_estimates_monthly)
1. Calculate Total SMAU (with estimate)
    * **Total Self-Managed SMAU (with estimate) = Recorded SMAU / % of seats reporting `usage_activity_by_stage_monthly.create.action_monthly_active_users_project_repo` = 1M / 53% = 1.9M**
    * **Estimated uplift = (Recorded SMAU / % of seats reporting `usage_activity_by_stage_monthly.create.action_monthly_active_users_project_repo`) - Recorded SMAU = 1.9M - 1M = 0.9M**
    * **Total SMAU (with estimate) = 1.0M (Recorded Self-Managed) + 0.9M (Estimated Self-Managed Uplift) + 800K (SaaS) = 2.7M**
    * This occurs in [`rpt_ping_metric_totals_w_estimates_monthly`](https://gitlab-data.gitlab.io/analytics/#!/model/model.gitlab_snowflake.rpt_ping_metric_totals_w_estimates_monthly)

<!--- Optional content that we could pull back into an example or elsewhere on the page in a future iteration
    * The 1000000 seats are split into 3 buckets:
      1. Seats reporting `usage_activity_by_stage_monthly.create.action_monthly_active_users_project_repo`: 530000 seats
      2. Seats not reporting `usage_activity_by_stage_monthly.create.action_monthly_active_users_project_repo`: 170000 seats
      3. Seats that did not send service ping: 300000 seats
--->

### Areas of opportunity for iteration

Based on the assumptions called out above, we know that there are opportunities to iterate on 
the current methodologies. Here are some areas we can explore.

* We could also break down the ratio applied per plan/tier (including free vs paid)
  * One current challenge: a subscription can have 2 installations from 2 different product tiers
* We could find a way to layer version adoption rate into the estimation
  * We know that paid installations tend to adopt new versions faster than free installations, 
  so this would be a substantial improvement in estimating free/Core usage
* We could add measures based on _paid_ subscriptions and seats associated with _paid_ 
subscriptions
  * There is a placeholder issue to explore this methodology [here](https://gitlab.com/gitlab-data/analytics/-/issues/12818)

### Feedback

Please add feedback to [this issue](https://gitlab.com/gitlab-data/analytics/-/issues/13068)
